<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="author" content="">

<link href="https://unpkg.com/tailwindcss@^1.0/dist/tailwind.min.css" rel="stylesheet">
<script src="https://use.fontawesome.com/releases/v6.7.2/js/all.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/konpa/devicon@master/devicon.min.css">
<link rel="stylesheet" href="/css/navbar.css" />
<link rel="stylesheet" href="/css/index.css" />

<script type="text/javascript">
 window.addEventListener('scroll', ()=>{
     const nav = document.querySelector('nav')
     nav.classList.toggle('onscroll', window.scrollY > 0)
 })
</script>

    <title>Diane Larlus&#39;s Personal Page</title>
  </head>
  <body>
      <nav class="pl-4 md:pl-24">
  <a href="/" class="logo">Home</a>
  <ul class="hidden md:flex">
    
    <li>
      <a href="/#News">News</a>
    </li>
    
    <li>
      <a href="/#Recent%20talks">Recent talks</a>
    </li>
    
    <li>
      <a href="/#Teaching">Teaching</a>
    </li>
    
  </ul>
</nav>
<section class="banner"></section>

      <div>
    <div
        id="mainBG"
        style="background-image: url('https://picsum.photos/id/830/1920/1080');"
    >
        <div
            class="wave wave1"
            style="background-image: url('/img/wave.png');"
            ></div>
        <div
            class="wave wave2"
            style="background-image: url('/img/wave.png');"
        ></div>
        <div
            class="wave wave3"
            style="background-image: url('/img/wave.png');"
        ></div>
        <div
            class="wave wave4"
            style="background-image: url('/img/wave.png');"
        ></div>
        <div class="centerAll">
            <div class="title text-6xl font-bold text-center">
                Diane Larlus
            </div>

            <div class="text text-xl text-center">Computer Vision &amp; Machine Learning Research Scientist</div>
        </div>
    </div>

    <main class="container mx-auto mt-0 px-4 xl:px-0">
    <section id="News" class="mt-12">
        <div class="flex justify-center">
            <div class="text-3xl title-deco tracking-wide">
                News
            </div>
        </div>
        <div>
            <p>2022</p>
<ul>
<li>Co-organizing the <a href="https://sslwin.org/">Self Supervised Learning: What is Next?</a> workshop at <a href="https://eccv2022.ecva.net/"><strong>ECCV22</strong></a></li>
<li>Paper accepted at <a href="https://3dvconf.github.io/2022/"><strong>3DV22</strong></a>: <em>Neural Feature Fusion Fields: 3D Distillation of Self-Supervised 2D Image Representations</em> [<a href="https://arxiv.org/abs/2209.03494">paper</a>, <a href="https://www.robots.ox.ac.uk/~vadim/n3f/">project page</a>, <a href="https://youtu.be/qAIpStmMHjY">video</a>]</li>
<li>Keynote speaker at the joint <a href="https://caprfiap2022.sciencesconf.org/"><strong>CAp-RFIAP 2022</strong></a> conference</li>
<li>Paper accepted at <a href="https://eccv2022.ecva.net/"><strong>ECCV22</strong></a>: <em>Granularity-aware Adaptation for Image Retrieval over Multiple Retrieval Tasks</em> [<a href="https://arxiv.org/abs/2210.02254">paper</a>]</li>
<li>Manuscript accepted to the <a href="https://www.jmlr.org/tmlr/"><strong>TMLR</strong></a> journal: <em>TLDR: Twin Learning for Dimensionality Reduction</em> [<a href="https://openreview.net/forum?id=86fhqdBUbx">paper</a>,<a href="https://github.com/naver/tldr">code</a>]</li>
<li>Invited talk at the <a href="https://asu-apg.github.io/odrum/"><strong>O-DRUM</strong></a> workshop at <a href="https://cvpr2022.thecvf.com/"><strong>CVPR22</strong></a></li>
<li>Paper accepted at <a href="https://cvpr2022.thecvf.com/"><strong>CVPR22</strong></a>: <em>On the Road to Online Adaptation for Semantic Image Segmentation</em> [<a href="https://arxiv.org/abs/2203.16195">paper</a>, <a href="https://github.com/naver/oasis">code and benchmark</a>]</li>
<li>2 papers accepted at <a href="https://iclr.cc/"><strong>ICLR22</strong></a>
<ul>
<li><em>ARTEMIS: Attention-based Retrieval with Text-Explicit Matching and Implicit Similarity</em> [<a href="https://arxiv.org/abs/2203.08101">paper</a>]</li>
<li><em>Learning Super-Features for Image Retrieval</em> [<a href="https://arxiv.org/abs/2201.13182">paper</a>,<a href="https://github.com/naver/FIRe">code</a>]</li>
</ul>
</li>
<li>Co-organizing the <a href="https://meta.wikimedia.org/wiki/Wiki-M3L"><strong>Wiki-M3L</strong></a> workshop at <a href="https://iclr.cc/"><strong>ICLR22</strong></a></li>
<li>Area Chair for <a href="http://cvpr2022.thecvf.com/"><strong>CVPR22</strong></a></li>
</ul>
<p>2021</p>
<ul>
<li>Paper accepted at <a href="https://3dv2021.surrey.ac.uk/"><strong>3DV21</strong></a>: <em>NeuralDiff: Segmenting 3D objects that move in egocentric videos</em> [<a href="https://arxiv.org/abs/2110.09936">paper</a>, <a href="https://www.robots.ox.ac.uk/~vadim/neuraldiff/">project page</a>, <a href="https://youtu.be/Ong_ITRSmns">video</a>]</li>
<li>Co-organizing the <a href="https://sites.google.com/view/imagenet-workshop/">ImageNet Past, Present, Future</a> workshop at <a href="https://nips.cc/Conferences/2021"><strong>NeurIPS21</strong></a></li>
<li>Paper accepted at <a href="http://iccv2021.thecvf.com/home"><strong>ICCV21</strong></a>: <em>Concept Greneralization in visual representations</em>  [<a href="https://europe.naverlabs.com/research/computer-vision/cog-benchmark/">project page</a>, <a href="https://www.youtube.com/watch?v=1pMkHaETA6U">video</a>, <a href="https://github.com/naver/cog">code</a>]</li>
<li>Co-organizing of the <a href="https://project.inria.fr/paiss/">PAISS Summer School 2021</a> (organized by <a href="https://miai.univ-grenoble-alpes.fr/">MIAI</a>, <a href="https://prairie-institute.fr/">PRAIRIE</a> and <a href="https://europe.naverlabs.com/">NAVER LABS Europe</a>)</li>
<li>Invited talk at the <a href="https://sites.google.com/view/wicvcvpr2021/home">Women in Computer Vision (WiCV) Workshop</a> at <a href="http://cvpr2021.thecvf.com"><strong>CVPR21</strong></a> [<a href="https://drive.google.com/file/d/1csYrvkJVNzyZqgZ9Id-K50wdLxem5NT2/view">Video</a>]</li>
<li>Invited talk at the <a href="https://aniti.univ-toulouse.fr/">ANITI</a> research institute (<a href="https://aniti.univ-toulouse.fr/2021/05/04/diane-larlus-lifelong-visual-representation-learning-from-weak-supervision-mitigating-catastrophic-forgetting">scientific seminar</a>)</li>
<li>2 papers accepted at <a href="http://cvpr2021.thecvf.com/"><strong>CVPR21</strong></a>
<ul>
<li><em>Probabilistic Embeddings for Cross-Modal Retrieval</em> [<a href="https://arxiv.org/abs/2101.05068">paper</a>, <a href="https://github.com/naver-ai/pcme">code</a>]</li>
<li><em>Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning</em> (<strong>oral</strong>) [<a href="https://arxiv.org/abs/2012.04324">paper</a>, <a href="https://europe.naverlabs.com/research/computer-vision/continual-adaptation-of-visual-representations-via-domain-randomization-and-meta-learning/">project page</a>]</li>
</ul>
</li>
<li>2 papers accepted at <a href="http://wacv2021.thecvf.com/home"><strong>WACV21</strong></a>
<ul>
<li><em>Unsupervised meta-domain adaptation for fashion retrieval</em> [<a href="https://openaccess.thecvf.com/content/WACV2021/html/Sharma_Unsupervised_Meta-Domain_Adaptation_for_Fashion_Retrieval_WACV_2021_paper.html">paper</a>, <a href="https://github.com/vivoutlaw/UDMA">code</a>, <a href="https://www.youtube.com/watch?v=3v8cBcj6KyQ">video</a>]</li>
<li><em>StacMR: Scene-Text Aware Cross-Modal Retrieval</em> [<a href="https://openaccess.thecvf.com/content/WACV2021/html/Mafla_StacMR_Scene-Text_Aware_Cross-Modal_Retrieval_WACV_2021_paper.html">paper</a>, <a href="https://github.com/AndresPMD/StacMR">code</a>, <a href="https://www.youtube.com/watch?v=gkNKt7OOtis">video</a>]</li>
</ul>
</li>
<li>Area Chair for <a href="http://cvpr2021.thecvf.com/"><strong>CVPR21</strong></a>, <a href="http://www.mva-org.jp/mva2021/"><strong>MVA21</strong></a>, <a href="http://iccv2021.thecvf.com/home"><strong>ICCV21</strong></a>, <a href="https://www.bmvc2021.com/"><strong>BMVC21</strong></a></li>
</ul>
<p>2020</p>
<ul>
<li>Best reviewer award at <a href="https://neurips.cc/Conferences/2020"><strong>NeurIPS20</strong></a></li>
<li>Keynote speaker at the <a href="https://miai.univ-grenoble-alpes.fr/actualites/miai-grenoble-alpes-organise-le-miai-day-dans-le-cadre-du-festival-transfo--842094.htm"><strong>MIAI DAY 2020</strong></a> event</li>
<li>Paper accepted at <a href="https://neurips.cc/Conferences/2020"><strong>NeurIPS20</strong></a>: <em>Hard negative mixing for contrastive learning</em> [<a href="https://europe.naverlabs.com/research/computer-vision/mochi/">project page</a>, <a href="https://vimeo.com/488154516">video</a>]</li>
<li>Invited talk at the Instance-Level Recognition <a href="https://ilr-workshop.github.io/ECCVW2020/"><strong>Workshop at ECCV20</strong></a> [<a href="https://www.youtube.com/watch?v=-wMv3HlRUDc">video</a>]</li>
<li>Paper accepted at <a href="https://eccv2020.eu/"><strong>ECCV20</strong></a>: <em>Learning Visual Representations with Caption Annotations</em> [<a href="https://europe.naverlabs.com/research/computer-vision/icmlm/">project page</a>, <a href="https://europe.naverlabs.com/blog/learning-visual-representations-with-caption-annotations-2/">blog</a>]</li>
<li>Joined as Editor for <a href="https://www.springer.com/journal/11263"><strong>International Journal of Computer Vision</strong></a></li>
<li>Industrial chair at <a href="https://eccv2020.eu/"><strong>ECCV20</strong></a></li>
<li>Area Chair for <a href="https://eccv2020.eu/"><strong>ECCV20</strong></a> and <a href="http://cvpr2020.thecvf.com/"><strong>CVPR20</strong></a></li>
</ul>
<p>2019</p>
<ul>
<li>Paper accepted at <a href="https://iccv2019.thecvf.com/"><strong>ICCV19</strong></a>: <em>Fine-Grained Action Retrieval through Multiple Parts-of-Speech Embeddings</em>  [<a href="https://mwray.github.io/FGAR/">project page</a>, <a href="https://youtu.be/FLSlRQBFow0">video</a>]</li>
<li>Area Chair for <a href="https://iccv2019.thecvf.com/"><strong>ICCV19</strong></a></li>
<li>Co-organizing the <a href="https://project.inria.fr/usad/ffss-usad-cvpr-2019/">FFSS-USAD workshop</a> at <strong>CVPR19</strong></li>
<li>Invited talk at the <a href="https://data-institute.univ-grenoble-alpes.fr/statlearn-2019-777167.htm"><strong>StatLearn 19</strong></a> conference</li>
</ul>
<p>2018</p>
<ul>
<li>Invited speaker, AI and Vision session at <a href="https://univ-cotedazur.fr/events-uca/sophia-summit#menu_1"><strong>SophIA Summit 2018</strong></a></li>
<li>Paper accepted at <a href="https://eccv2018.org/"><strong>ECCV18</strong></a>: <em>Semi-Convolutional Operators for Instance Segmentation</em> [<a href="https://arxiv.org/abs/1807.10712">paper</a>]</li>
<li>Our work on <em>Capturing the Geometry of Object Categories from Video Supervision</em> has been accepted to <strong>TPAMI</strong></li>
<li><a href="https://cvpr2018.thecvf.com/"><strong>CVPR18</strong></a> outstanding reviewer award</li>
<li>Lecture about visual search at the PRAIRIE Artificial Intelligence summer school <a href="https://project.inria.fr/paiss/program-2018/"><strong>PAISS 2018</strong></a></li>
<li>Paper accepted at <a href="https://cvpr2018.thecvf.com/"><strong>CVPR18</strong></a>: <em>Self-supervised Learning of Geometrically Stable Features Through Probabilistic Introspection</em> (<strong>spotlight</strong>) [<a href="https://www.robots.ox.ac.uk/~vgg/research/probabilistic_introspection/">project page</a>, <a href="https://youtu.be/Jl1NeziAHFY?t=5237">video</a>]</li>
</ul>
<p>Back to the <a href="/index.html">Main Page</a></p>

        </div>
    </section>
</div>
    </main>
</div>

      <footer class="text-center mt-8 py-2 bg-gray-900 text-white">
  <div>&copy; 2025 Diane Larlus - Hugo (SimpleIntro)</div>
</footer>

  </body>
</html>
