<!DOCTYPE html>
<html lang="en-us">
  <head>
	<meta name="generator" content="Hugo 0.82.0" />
    <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="author" content="Diane Larlus">

<link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
<link href="https://unpkg.com/tailwindcss@^1.0/dist/tailwind.min.css" rel="stylesheet">
<script src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/konpa/devicon@master/devicon.min.css">
<link rel="stylesheet" href="/css/navbar.css" />
<link rel="stylesheet" href="/css/index.css" />



<script type="text/javascript">
 window.addEventListener('scroll', ()=>{
     const nav = document.querySelector('nav')
     nav.classList.toggle('onscroll', window.scrollY > 0)
 })
</script>

    <title>Diane Larlus&#39;s Personal Page</title>
  </head>
  <body>
      <nav class="pl-4 md:pl-24">
  <a href="" class="logo">Diane Larlus&#39;s Personal Page</a>
  <ul class="hidden md:flex">
    
    <li>
      <a href="/#News">News</a>
    </li>
    
    <li>
      <a href="/#Recent%20talks">Recent talks</a>
    </li>
    
    <li>
      <a href="/#Teaching">Teaching</a>
    </li>
    
  </ul>
</nav>
<section class="banner"></section>

      <div>
    <div
        id="mainBG"
        style="background-image: url('https://picsum.photos/id/830/1920/1080');"
    >
        <div
            class="wave wave1"
            style="background-image: url('/img/wave.png');"
        ></div>
        <div
            class="wave wave2"
            style="background-image: url('/img/wave.png');"
        ></div>
        <div
            class="wave wave3"
            style="background-image: url('/img/wave.png');"
        ></div>
        <div
            class="wave wave4"
            style="background-image: url('/img/wave.png');"
        ></div>
        <div class="centerAll">
            <div class="title text-6xl font-bold text-center">
                Diane Larlus
            </div>

            <div class="text text-xl text-center">Computer Vision &amp; Machine Learning Research Scientist</div>
        </div>
    </div>
    

    <main class="container mx-auto mt-0 px-4 xl:px-0">
        <section id="about" class="md:flex justify-around">
            <div class="my-auto md:mr-4">
                <img
                    class="w-32 h-32 rounded-full"
                    src="img/diane.jpg"
                    alt="Profile"
                />
                <div class="text-3xl title-deco tracking-wide">
  About Me
</div>

                <div class="flex mt-3 gap-3 text-xl">
                    
                    <a href="mailto:diane.larlus@naverlabs.com"><i class="fas fa-envelope"></i></a>
                    <a href="https://scholar.google.com.au/citations?user=nI2oJqkAAAAJ&amp;hl=en"><i class="fas fa-graduation-cap"></i></a>
                    <a href="https://twitter.com/dlarlus"><i class="fab fa-twitter"></i></a>
                </div>
            </div>
            <div class="mt-4 md:mt-0 md:ml-0">
                <div class="text-2xl font-bold">
                    Researcher at Naver Labs Europe and MIAI Grenoble
                </div>
                <div class="text-lg mt-3">
                    <div>
                        Principal research scientist at Naver Labs Europe working on computer vision and machine learning.<br />Chair holder on Life-long representation learning within the MIAI AI research institute of Grenoble.<br />Working towards a semantic understanding of visual scenes.<br />Currently interested in lifelong learning and continual domain adaptation.<br />Prior and current work on instance-level, semantic, and cross-modal visual search.<br />
                        
                    </div>
                </div>
            </div>
        </section>

        <section id="projects" class="mt-12">
            <div class="md:flex justify-center">
                <div class="text-3xl title-deco tracking-wide">
  Projects
</div>

            </div>
            
            
            <div
                class="mt-8 grid grid-flow-row grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4"
            >
                
                <div class="w-full rounded overflow-hidden shadow-lg">
                    <a href="https://www.robots.ox.ac.uk/~vadim/neuraldiff/" target="_blank">
                        <img
                            class="w-full h-48"
                            src="img/neuraldiff.png"
                            alt="Sunset in the mountains"
                        />            
                    </a>         
                    <div class="px-6 py-4">
                        <div class="font-bold text-xl mb-2">NeuralDiff @3DV21</div>
                        <p class="text-gray-700 text-base">
                                    A neural rendering method to segment semi-static objects out of their background in egocentric videos.
        Collaboration with VGG, Oxford. 
        3DV 2021
    
                        </p>
                    </div>
                </div>
                
                <div class="w-full rounded overflow-hidden shadow-lg">
                    <a href="https://europe.naverlabs.com/research/computer-vision/cog-benchmark/" target="_blank">
                        <img
                            class="w-full h-48"
                            src="img/cog.png"
                            alt="Sunset in the mountains"
                        />            
                    </a>         
                    <div class="px-6 py-4">
                        <div class="font-bold text-xl mb-2">CoG @ICCV21</div>
                        <p class="text-gray-700 text-base">
                                    A concept generalization benchmark for visual representation, named ImageNet-CoG.
        Collaboration with Inria. 
        ICCV 2021
    
                        </p>
                    </div>
                </div>
                
                <div class="w-full rounded overflow-hidden shadow-lg">
                    <a href="https://arxiv.org/abs/2101.05068" target="_blank">
                        <img
                            class="w-full h-48"
                            src="img/pcme.png"
                            alt="Sunset in the mountains"
                        />            
                    </a>         
                    <div class="px-6 py-4">
                        <div class="font-bold text-xl mb-2">PCME @CVPR21</div>
                        <p class="text-gray-700 text-base">
                                    Learning Probabilistic Embedding for Cross-Modal Retrieval (PCME).
        Collaboration with Naver AI, CLOVA. 
        CVPR 2021
    
                        </p>
                    </div>
                </div>
                
                <div class="w-full rounded overflow-hidden shadow-lg">
                    <a href="https://arxiv.org/abs/2012.04324" target="_blank">
                        <img
                            class="w-full h-48"
                            src="img/cda.png"
                            alt="Sunset in the mountains"
                        />            
                    </a>         
                    <div class="px-6 py-4">
                        <div class="font-bold text-xl mb-2">Continual DA @CVPR21</div>
                        <p class="text-gray-700 text-base">
                                    Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning. CVPR 2021 (oral). 
    
                        </p>
                    </div>
                </div>
                
                <div class="w-full rounded overflow-hidden shadow-lg">
                    <a href="https://europe.naverlabs.com/research/computer-vision/mochi/" target="_blank">
                        <img
                            class="w-full h-48"
                            src="img/mochi.png"
                            alt="Sunset in the mountains"
                        />            
                    </a>         
                    <div class="px-6 py-4">
                        <div class="font-bold text-xl mb-2">MoCHi @NeurIPS20</div>
                        <p class="text-gray-700 text-base">
                                Hard Negative Mixing for Contrastive Learning. NeurIPS 2020. 
    
                        </p>
                    </div>
                </div>
                
                <div class="w-full rounded overflow-hidden shadow-lg">
                    <a href="https://europe.naverlabs.com/research/computer-vision/icmlm/" target="_blank">
                        <img
                            class="w-full h-48"
                            src="img/icmlm.gif"
                            alt="Sunset in the mountains"
                        />            
                    </a>         
                    <div class="px-6 py-4">
                        <div class="font-bold text-xl mb-2">ICMLM @ECCV20</div>
                        <p class="text-gray-700 text-base">
                                Image Conditioned Masked Language Modeling as a proxy task to learn visual representations from scratch. ECCV 2020. 
    
                        </p>
                    </div>
                </div>
                
                <div class="w-full rounded overflow-hidden shadow-lg">
                    <a href="https://mwray.github.io/FGAR/" target="_blank">
                        <img
                            class="w-full h-48"
                            src="img/jpose.png"
                            alt="Sunset in the mountains"
                        />            
                    </a>         
                    <div class="px-6 py-4">
                        <div class="font-bold text-xl mb-2">JPoSE @ICCV19</div>
                        <p class="text-gray-700 text-base">
                              
    Fine-Grained Action Retrieval through Multiple Parts-of-Speech Embeddings. ICCV 2019. 
    
                        </p>
                    </div>
                </div>
                
                <div class="w-full rounded overflow-hidden shadow-lg">
                    <a href="https://www.robots.ox.ac.uk/~vgg/research/probabilistic_introspection/" target="_blank">
                        <img
                            class="w-full h-48"
                            src="img/ssl_geometry.png"
                            alt="Sunset in the mountains"
                        />            
                    </a>         
                    <div class="px-6 py-4">
                        <div class="font-bold text-xl mb-2">SSL for Geometry @CVPR18</div>
                        <p class="text-gray-700 text-base">
                                Self-supervised Learning of Geometrically Stable Features Through Probabilistic Introspection. CVPR 2018 (spotlight). 
    
                        </p>
                    </div>
                </div>
                
            </div>
            
        </section>


        
        
          
        
          
        
          <section id="News" class="mt-12">
            <div class="flex justify-center">
                <div class="text-3xl title-deco tracking-wide">
                    News
                </div>
            </div>
            <div>
                <p>2021</p>
<ul>
<li>Paper accepted at <a href="https://3dv2021.surrey.ac.uk/"><strong>3DV21</strong></a>: <em>NeuralDiff: Segmenting 3D objects that move in egocentric videos</em> [<a href="https://arxiv.org/abs/2110.09936">paper</a>, <a href="https://www.robots.ox.ac.uk/~vadim/neuraldiff/">project page</a>, <a href="https://youtu.be/Ong_ITRSmns">video</a>]</li>
<li>Co-organizing the <a href="https://sites.google.com/view/imagenet-workshop/">ImageNet Past, Present, Future</a> workshop at <strong>NeurIPS20</strong></li>
<li>Paper accepted at <a href="http://iccv2021.thecvf.com/home"><strong>ICCV21</strong></a>: <em>Concept Greneralization in visual representations</em>  [<a href="https://europe.naverlabs.com/research/computer-vision/cog-benchmark/">project page</a>, <a href="https://www.youtube.com/watch?v=1pMkHaETA6U">video</a>, <a href="https://github.com/naver/cog">code</a>]</li>
<li>I&rsquo;m one of the organizers of the <a href="https://project.inria.fr/paiss/">PAISS Summer School 2021</a> (organized by <a href="https://miai.univ-grenoble-alpes.fr/">MIAI</a>, <a href="https://prairie-institute.fr/">PRAIRIE</a> and <a href="https://europe.naverlabs.com/">NAVER LABS Europe</a>)</li>
<li>Invited talk at the <a href="https://sites.google.com/view/wicvcvpr2021/home">Women in Computer Vision (WiCV) Workshop</a> at CVPR21 [<a href="https://drive.google.com/file/d/1csYrvkJVNzyZqgZ9Id-K50wdLxem5NT2/view">Video</a>]</li>
<li>Invited talk at the <a href="https://aniti.univ-toulouse.fr/">ANITI</a> research institute (<a href="https://aniti.univ-toulouse.fr/2021/05/04/diane-larlus-lifelong-visual-representation-learning-from-weak-supervision-mitigating-catastrophic-forgetting">scientific seminar</a>)</li>
<li>2 papers accepted at <a href="http://cvpr2021.thecvf.com/"><strong>CVPR21</strong></a>
<ul>
<li><em>Probabilistic Embeddings for Cross-Modal Retrieval</em> [<a href="https://arxiv.org/abs/2101.05068">paper</a>, <a href="https://github.com/naver-ai/pcme">code</a>]</li>
<li><em>Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning</em> (<strong>oral</strong>) [<a href="https://arxiv.org/abs/2012.04324">paper</a>, <a href="XX">blog</a>]</li>
</ul>
</li>
<li>Area Chair for <a href="http://cvpr2021.thecvf.com/"><strong>CVPR21</strong></a>, <a href="http://www.mva-org.jp/mva2021/"><strong>MVA21</strong></a>, <a href="http://iccv2021.thecvf.com/home"><strong>ICCV21</strong></a>, <a href="https://www.bmvc2021.com/"><strong>BMVC21</strong></a></li>
<li>2 papers accepted at <a href="http://wacv2021.thecvf.com/home"><strong>WACV21</strong></a>
<ul>
<li><em>Unsupervised meta-domain adaptation for fashion retrieval</em> [<a href="https://openaccess.thecvf.com/content/WACV2021/html/Sharma_Unsupervised_Meta-Domain_Adaptation_for_Fashion_Retrieval_WACV_2021_paper.html">paper</a>, <a href="https://github.com/vivoutlaw/UDMA">code</a>, <a href="https://www.youtube.com/watch?v=3v8cBcj6KyQ">video</a>]</li>
<li><em>StacMR: Scene-Text Aware Cross-Modal Retrieval</em> [<a href="https://openaccess.thecvf.com/content/WACV2021/html/Mafla_StacMR_Scene-Text_Aware_Cross-Modal_Retrieval_WACV_2021_paper.html">paper</a>, <a href="https://github.com/AndresPMD/StacMR">code</a>, <a href="https://www.youtube.com/watch?v=gkNKt7OOtis">video</a>]</li>
</ul>
</li>
</ul>
<p>2020</p>
<ul>
<li>Best reviewer award at <a href="https://neurips.cc/Conferences/2020"><strong>NeurIPS20</strong></a></li>
<li>Keynote speaker at the <a href="https://miai.univ-grenoble-alpes.fr/actualites/miai-grenoble-alpes-organise-le-miai-day-dans-le-cadre-du-festival-transfo--842094.htm"><strong>MIAI DAY 2020</strong></a> event</li>
<li>Paper accepted at <a href="https://neurips.cc/Conferences/2020"><strong>NeurIPS20</strong></a>: <em>Hard negative mixing for contrastive learning</em> [<a href="https://europe.naverlabs.com/research/computer-vision/mochi/">project page</a>, <a href="https://vimeo.com/488154516">video</a>]</li>
<li>Invited talk at the Instance-Level Recognition <a href="https://ilr-workshop.github.io/ECCVW2020/"><strong>Workshop at ECCV20</strong></a> [<a href="https://www.youtube.com/watch?v=-wMv3HlRUDc">video</a>]</li>
<li>Paper accepted at <a href="https://eccv2020.eu/"><strong>ECCV20</strong></a>: <em>Learning Visual Representations with Caption Annotations</em> [<a href="https://europe.naverlabs.com/research/computer-vision/icmlm/">project page</a>, <a href="https://europe.naverlabs.com/blog/learning-visual-representations-with-caption-annotations-2/">blog</a>]</li>
<li>Industrial chair at <a href="https://eccv2020.eu/"><strong>ECCV20</strong></a></li>
<li>Area Chair for <a href="https://eccv2020.eu/"><strong>ECCV20</strong></a>,  <a href="http://cvpr2020.thecvf.com/"><strong>CVPR20</strong></a></li>
</ul>
<p>2019</p>
<ul>
<li>Paper accepted at <a href="https://iccv2019.thecvf.com/"><strong>ICCV19</strong></a>: <em>Fine-Grained Action Retrieval through Multiple Parts-of-Speech Embeddings</em>  [<a href="https://mwray.github.io/FGAR/">project page</a>, <a href="https://youtu.be/FLSlRQBFow0">video</a>]</li>
<li>Area Chair for <a href="https://iccv2019.thecvf.com/"><strong>ICCV19</strong></a></li>
<li>Co-organizing the <a href="https://project.inria.fr/usad/ffss-usad-cvpr-2019/">FFSS-USAD workshop</a> at <strong>CVPR19</strong></li>
<li>Invited talk at the <a href="https://data-institute.univ-grenoble-alpes.fr/statlearn-2019-777167.htm"><strong>StatLearn 19</strong></a> conference</li>
</ul>
<p>More:</p>
<ul>
<li>see <a href="/older_news">Older news</a></li>
<li>see <a href="/publications">Full list of publications</a></li>
</ul>

            </div>
          </section>
          
          
        
          <section id="Recent talks" class="mt-12">
            <div class="flex justify-center">
                <div class="text-3xl title-deco tracking-wide">
                    Recent talks
                </div>
            </div>
            <div>
                <table>
<thead>
<tr>
<th style="text-align:right">  </th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>June 2021</strong></td>
<td> </td>
<td>Invited talk at the <a href="https://sites.google.com/view/wicvcvpr2021/home">Women in Computer Vision (WiCV) Workshop</a> at CVPR21 - <em>Lifelong visual representation learning</em> [<a href="https://drive.google.com/file/d/1csYrvkJVNzyZqgZ9Id-K50wdLxem5NT2/view">Video</a>]</td>
</tr>
<tr>
<td style="text-align:right"><strong>May 2021</strong></td>
<td></td>
<td>Invited talk at the <a href="https://aniti.univ-toulouse.fr/">ANITI</a> research institute (<a href="https://aniti.univ-toulouse.fr/2021/05/04/diane-larlus-lifelong-visual-representation-learning-from-weak-supervision-mitigating-catastrophic-forgetting">scientific seminar</a>) - <em>Learning from weak supervision and mitigating catastrophic forgetting</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>October 2020</strong></td>
<td></td>
<td>Keynote Speaker for <a href="https://miai.univ-grenoble-alpes.fr/events-highlights/miai-days/miai-grenoble-alpes-organises-the-miai-day-within-the-framework-of-the-festival-tansfo-2020-845085.htm?RH=1617121028074">MIAI Days</a> - <em>Lifelong visual representation learning</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>August 2020</strong></td>
<td></td>
<td>Invited talk at the ILR Workshop at ECCV20  - <em>From Instance-Level to Semantic Image Retrieval</em> [<a href="https://www.youtube.com/watch?v=-wMv3HlRUDc&amp;t=1s">Video</a>]</td>
</tr>
<tr>
<td style="text-align:right"><strong>November 2019</strong></td>
<td></td>
<td>Invited talk at the <a href="http://thoth.inrialpes.fr/people/mairal/solaris/workshop2019/">SOLARIS Workshop</a> -  <em>Self-supervised learning for category-level geometry estimation</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>April 2019</strong></td>
<td></td>
<td>Invited talk at the <a href="https://www.sfds.asso.fr/">StatLearn</a> 19 conference - <em>Learning Image Representations for Efficient Visual Search</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>November 2018</strong></td>
<td></td>
<td>Invited speaker, AI and Vision session at <a href="https://univ-cotedazur.fr/events-uca/sophia-summit">SophIA Summit</a> - <em>Visual Search</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>July 2018</strong></td>
<td></td>
<td>Lecture at the PRAIRIE Artificial Intelligence summer school (<a href="https://project.inria.fr/paiss/home-2018/">PAISS</a>) [<a href="thoth.inrialpes.fr/workshop/paiss2018/larlus-visual-search.pdf">slides</a>] - <strong>Visual Search</strong></td>
</tr>
<tr>
<td style="text-align:right"></td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:right"></td>
<td></td>
<td><strong>Older</strong>: see CV</td>
</tr>
</tbody>
</table>

            </div>
          </section>
          
          
        
          <section id="Teaching" class="mt-12">
            <div class="flex justify-center">
                <div class="text-3xl title-deco tracking-wide">
                    Teaching
                </div>
            </div>
            <div>
                <table>
<thead>
<tr>
<th style="text-align:right">  </th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right"><strong>2021/2022</strong></td>
<td> </td>
<td>Comprendre des données visuelles à grande échelle - <em>ENSIMAG, Grenoble</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>May 2021</strong></td>
<td> </td>
<td>Guest lecture on Visual Search  - <em>Hanoi University of Science and Technology (HUST), Vietnam</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>2020/2021</strong></td>
<td> </td>
<td>Comprendre des données visuelles à grande échelle - <em>ENSIMAG, Grenoble</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>2020</strong></td>
<td></td>
<td>Découvrir l’intelligence artificielle par le jeu (<em>Discover AI with games</em> is a 2 day training session for high school teachers) - <em>Maison pour la Science Alpes-Dauphiné</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>Nov 2019</strong></td>
<td> </td>
<td>Lecture on Visual Search as part of the &lsquo;Deep Learning&rsquo; course for the MVA master - <em>ENS Paris</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>2019/2020</strong></td>
<td> </td>
<td>Comprendre des données visuelles à grande échelle - <em>ENSIMAG, Grenoble</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>Feb 2019</strong></td>
<td></td>
<td>Lecture on Visual Search as part of the &lsquo;Deep Learning in Practice&rsquo; course for the MVA master - <em>ENS Paris</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>2018/2019</strong></td>
<td></td>
<td>Comprendre des données visuelles à grande échelle - <em>ENSIMAG, Grenoble</em></td>
</tr>
<tr>
<td style="text-align:right"><strong>July 2018</strong></td>
<td></td>
<td>Lecture on Visual Search at the <em>PRAIRIE Artificial Intelligence summer school (<a href="https://project.inria.fr/paiss/program-2018/">PAISS 2018</a>)</em>  [<a href="thoth.inrialpes.fr/workshop/paiss2018/larlus-visual-search.pdf">slides</a>]</td>
</tr>
<tr>
<td style="text-align:right"></td>
<td></td>
<td><strong>Older</strong>: see CV</td>
</tr>
</tbody>
</table>

            </div>
          </section>
          
          
    </main>
</div>


      <footer class="text-center mt-8 py-2 bg-gray-900 text-white">
  <div>&copy; 2021 Diane Larlus - Hugo (SimpleIntro)</div>
</footer>

  </body>
</html>
